{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_top_pattern(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Filter text containing 'top' or 'Top' pattern using regex\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if pattern found, False otherwise\n",
    "    \"\"\"\n",
    "    pattern = r'[tT]op'\n",
    "    return bool(re.search(pattern, text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_report_config(file_path: str = \"data/reports/alpha_report.json\") -> dict:\n",
    "    \"\"\"\n",
    "    Load report configuration from JSON file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to JSON config file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Loaded report configuration\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "report_config = load_report_config(r\"D:\\Desktop\\arb-refactor\\data\\reports\\alpha_report.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abbreviation(report_config) -> str:\n",
    "    \n",
    "    abbreviated_functions = []\n",
    "\n",
    "    for function_name, value in report_config.items():\n",
    "        abbreviation = ', '.join(value['function']['abbreviation'])\n",
    "        format_schema = f\"- {function_name}: {abbreviation}\"\n",
    "        abbreviated_functions.append(format_schema)\n",
    "    \n",
    "    abbreviated_functions_to_string = \"\\n\".join(abbreviated_functions)\n",
    "    return abbreviated_functions_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviated_functions_to_string = get_abbreviation(report_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_description(report_config) -> str:\n",
    "    function_descriptions = []\n",
    "    for function_name, value in report_config.items():\n",
    "        function_description = value['function']['description']\n",
    "        format_schema = f\"- {function_name}: {function_description}\"\n",
    "        function_descriptions.append(format_schema)\n",
    "        \n",
    "    function_descriptions_to_string = \"\\n\".join(function_descriptions)\n",
    "    return function_descriptions_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions_to_string = get_function_description(report_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_user_prompt(query: str) -> str:\n",
    "    prompt = \"\"\"\n",
    "        #📝Example requests and responses:\n",
    "        \n",
    "        Input: \"I need to see the win/loss report from last week\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"I want w/l report today\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"Show me wl report\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"Get WL please\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"Show me the w-l details\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"I need winlost stats\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"I want to get the turnover report\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/turnover\"\n",
    "        }}\n",
    "\n",
    "        Input: \"I want to take turnover report for user 123\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/turnover\"\n",
    "        }}\n",
    "\n",
    "        Input: \"Get me the get winlost report for March transactions\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "\n",
    "        Input: \"I want get performance of abc1 last week\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"Hello how are you today?\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"I want Sportsbook only\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"I want change to a little bit, I want to get Product Virtual Sports and product detail Saba Basketball with user level Super Agent\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"I want to get the top 20 outstanding\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/topoutstanding\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"The outstanding of Master1\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/outstanding\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"Top 40 Outstanding of Sportsbook\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/topoutstanding\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"My current outstanding\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/outstanding\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"Top 10 Outstanding of Sportsbook\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/topoutstanding\"\n",
    "        }}\n",
    "        \n",
    "        Input: \"wl today please\"\n",
    "        Output: {{\n",
    "            \"function_called\": \"/winlost_detail\"\n",
    "        }}\n",
    "        \n",
    "        Based on this request, which function should be called? Return only the JSON response.\n",
    "    \"\"\".format(query=query)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def functional_calling(query: str) -> str:\n",
    "    # API endpoint\n",
    "    url = \"http://10.5.10.110:8090/api/chat\"\n",
    "    \n",
    "    # Construct the system prompt using function metadata\n",
    "    system_prompt = \"\"\"\n",
    "    You are an AI assistant that helps determine which function to call based on user input.\n",
    "    Available functions:\n",
    "        {function_description}\n",
    "    - Try to recognize the function abbreviation from the user's request\n",
    "    - Function Abbreviations:\n",
    "        {abbreviation}\n",
    "    Determine which function best matches the user's request and return it in JSON format like:\n",
    "    {{\n",
    "        \"function_called\": \"/function_name\"\n",
    "    }}\n",
    "    \"\"\".format(\n",
    "        abbreviation=abbreviated_functions_to_string,\n",
    "        function_description=function_descriptions_to_string\n",
    "    )\n",
    "\n",
    "    # Construct the prompt for function determination with examples\n",
    "    user_prompt = get_user_prompt(query)\n",
    "\n",
    "    \n",
    "    format_schema =  {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"function_called\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the function to call\",\n",
    "                \"enum\": [\n",
    "                    '/winlost_detail',\n",
    "                    '/turnover',\n",
    "                    '/outstanding',\n",
    "                    '/topoutstanding',\n",
    "                    'N/A'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"function_called\"]\n",
    "    }\n",
    "\n",
    "    model = 'qwen2.5:14b'\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"format\": format_schema,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    return json.loads(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "example_inputs = queries = [\n",
    "    \"Get me a Win Loss Detail Report yesterday\",\n",
    "    \"Get me a Turnover Detail Report on day 10\",\n",
    "    \"Net Turnover Detail Report from 1/1 to 31/1\",\n",
    "    \"Get me a Win Loss Detail Report for Direct Member who played Product Detail Sportsbook in Sportsbook Product from 01/02/2024 to 15/02/2024\",\n",
    "    \"Give me my Win Loss Detail report  last week\",\n",
    "    \"Give me a Gross Commission Report Detail report for Sportsbook from last week.\",\n",
    "    \"Give me my Win Loss Detail report  last week\",\n",
    "    \"Get me a Company Report of master1\",\n",
    "    \"Win/Loss details for Product Sportsbook\",\n",
    "    \"Get me a Win Loss on day 10\",\n",
    "    \"I want Win Loss report of Sportsbook this week\",\n",
    "    \"I want get performance of abc1 last week\",\n",
    "    \"Live Casino Master report of Master master1 yesterday\",\n",
    "    \"I need Member report of Agent agent01 last week\",\n",
    "    \"Show me today's summary\",\n",
    "    \"How did we perform in live casino last week?\",\n",
    "    \"The amount I need to pay for master abc1 last week\",\n",
    "    \"Get report of master1\",\n",
    "    \"Win/Loss details for Product Sportsbook\",\n",
    "    \"Get me a Super Report of master1\"\n",
    "]\n",
    "\n",
    "for input_text in example_inputs:\n",
    "    called_function = functional_calling(input_text)\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Called function: {called_function['function_called']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/winlost_detail'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"turnover today please\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': 'N/A'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': 'N/A'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"I want Sportsbook only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_topoutstanding_report'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"give me top 20 outstanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_outstanding_report'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"give me outstanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_topoutstanding_report'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"I want to get the list of leading 20 outstanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_topoutstanding_report'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"give me the first 20 outstanding sorting from highest to lowest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_topoutstanding_report'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"give me the first 20 outstanding decreasing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_turnover_report'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"I want to get turnover report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': 'N/A'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"Do you know donald trump?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_called': '/get_outstanding_report'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_calling(\"How many outstanding do you have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Embedding data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Download from the 🤗 Hub\n",
    "model_embedding = SentenceTransformer(\"hiieu/halong_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def faiss_indexing(data_embeddings, path_save):\n",
    "    # indexing\n",
    "    cpu_index = faiss.IndexFlatIP(768)\n",
    "    for embedding in tqdm.tqdm(data_embeddings, colour='green', desc='Indexing'):\n",
    "        embedding = embedding.astype(np.float32).reshape(1, -1)\n",
    "        cpu_index.add(embedding)\n",
    "\n",
    "    # Save vector database\n",
    "    faiss.write_index(cpu_index, path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def bm25_indexing(contents, path_save):\n",
    "\n",
    "  tokenized_corpus = []\n",
    "  for doc in tqdm.tqdm(contents, colour='green', desc='Indexing'):\n",
    "    tokenized_corpus.append(doc)\n",
    "\n",
    "  with open(path_save, 'wb') as f:\n",
    "    pickle.dump(tokenized_corpus, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviated_functions_to_dict = {}\n",
    "abbreviated_functions_index = {}\n",
    "contents = []\n",
    "functions = []\n",
    "for function_name, value in report_config.items():\n",
    "    abbreviation = ', '.join(value['function']['abbreviation'])\n",
    "    abbreviated_functions_to_dict[function_name] = value['function']['abbreviation']\n",
    "    contents.extend(value['function']['abbreviation'])\n",
    "    functions.extend([function_name] * len(value['function']['abbreviation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|\u001b[32m██████████\u001b[0m| 36/36 [00:00<00:00, 36227.19it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(contents)\n",
    "faiss_indexing(embeddings, 'abbreviation_faiss.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|\u001b[32m██████████\u001b[0m| 36/36 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_indexing(contents, 'abbreviation_bm25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin(path):\n",
    "    cpu_index = faiss.read_index(path)\n",
    "    return cpu_index\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = load_bin('./abbreviation_faiss.index')\n",
    "bm25_index = load_pickle('./abbreviation_bm25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def bm25_keyword_search(query, bm25_index, topk=1):\n",
    "\n",
    "  bm25 = BM25Okapi(bm25_index)\n",
    "  docs = bm25.get_top_n(query, bm25_index, n=topk)\n",
    "  index = np.where(np.isin(contents, docs))[0].tolist()\n",
    "  return np.array(functions)[index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/outstanding', '/outstanding', '/topoutstanding', '/topoutstanding']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_keyword_search(\n",
    "    query=\"wl please\",\n",
    "    bm25_index=bm25_index,\n",
    "    topk=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, faiss_index, topk):\n",
    "  prompt_embedding = model_embedding.encode([query])\n",
    "  prompt_embedding = np.array(prompt_embedding)\n",
    "  scores, indices = faiss_index.search(prompt_embedding, topk)\n",
    "  print(scores)\n",
    "  return np.array(functions)[indices].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4937626  0.45274523 0.4524747  0.41575557]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/winlost_detail', '/winlost_detail', '/winlost_detail', '/winlost_detail']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_search(\n",
    "    query=\"wl please\",\n",
    "    faiss_index=faiss_index,\n",
    "    topk=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, topk):\n",
    "  contexts = semantic_search(query, faiss_index, topk)\n",
    "  contexts.extend(bm25_keyword_search(query, bm25_index, topk))\n",
    "  return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76f154b20ef4f62b5d31ebac6b8f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leon.pham\\AppData\\Local\\anaconda3\\envs\\langchain\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\leon.pham\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d794451e0de41119662dbbdfe3c624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7ca204c7844acdb9c4476e2af46fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac35b04ab7b34d10a1a5c954a088220a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79754213e014ff69a6e15c1e0f7a17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d92ddbb5a8e47c29a9168c89519b498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import torch.nn as nn\n",
    "\n",
    "model_reranking = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "def hybrid_search_with_reranking(query, topk):\n",
    "  contexts = hybrid_search(query, topk)\n",
    "  formated_contexts = [[query, context] for context in contexts]\n",
    "\n",
    "  scores = model_reranking.predict(formated_contexts, activation_fct=sigmoid)\n",
    "  top_k_values = np.sort(scores)[-topk:][::-1]\n",
    "\n",
    "  top_k_indices = np.argsort(scores)[-topk:][::-1]\n",
    "  print(top_k_values)\n",
    "\n",
    "  contexts = np.array(contexts)\n",
    "  best_contexts = contexts[top_k_indices].tolist()\n",
    "\n",
    "  return best_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6948472  0.59056854 0.5153476  0.50300705]]\n",
      "[3.5108358e-05 2.7640401e-05 2.7640401e-05 2.7640401e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/turnover', '/winlost_detail', '/winlost_detail', '/winlost_detail']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search_with_reranking(\n",
    "    query=\"wl\",\n",
    "    topk=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword + faiss -> OKE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from typing import Dict, Any\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class NERAgentConfig:\n",
    "    instruction: str = \"\"\"\n",
    "        # Define your task:\n",
    "        Extract the most relevant keywords from the following sentence: '{query}'. \n",
    "        Focus on important nouns that convey the core meaning. \n",
    "        Detect any words related to dates such as tomorrow, today, last week, next year, so on, following the example below.\n",
    "        Help me convert the date range to the format of YYYY-MM-DD to YYYY-MM-DD.\n",
    "        \n",
    "        # For date range, please help me convert it to from_date and to_date in DD/MM/YYYY format following these cases:\n",
    "\n",
    "        1. If a single date is mentioned (e.g. \"day 10\"):\n",
    "           - Use current month and year {current_year} and {current_month}\n",
    "           - Set both from_date and to_date to that date\n",
    "           Example: \"day 10\" -> from_date: 10/{current_month}/{current_year}, to_date: 10/{current_month}/{current_year}\n",
    "\n",
    "        2. If a date range is specified (e.g. \"01/02/2024 to 15/02/2024\"):\n",
    "            - Note that in this case, the date range derived from user's query must be DD/MM/YYYY format\n",
    "            - Keep the dates as specified in DD/MM/YYYY format\n",
    "           Example: \"01/02/2024 to 15/02/2024\" -> from_date: 01/02/2024, to_date: 15/02/2024\n",
    "\n",
    "        3. If relative dates are mentioned:\n",
    "           - \"today\" -> Use {current_date} for both\n",
    "           - \"yesterday\" -> Use yesterday's date for both from current date {current_date}\n",
    "           - \"last week\" -> from_date is 7 days ago, to_date is today from current date {current_date}\n",
    "           - \"last month\" -> from_date is 1st of previous month, to_date is last day of previous month from current date {current_date}\n",
    "           - \"last year\" -> from_date is Jan 1st of previous year, to_date is Dec 31st of previous year from current date {current_date}\n",
    "           - \"this week\" -> from_date is Monday of current week, to_date is today from current date {current_date}\n",
    "           - \"this month\" -> from_date is 1st of current month, to_date is today from current date {current_date}\n",
    "           - \"this year\" -> from_date is Jan 1st of current year, to_date is today from current date {current_date}\n",
    "           \n",
    "        4. If a month range is specified (e.g. \"1/1 to 31/1\"):\n",
    "           - Use current year {current_year}\n",
    "           - Set from_date to first day of specified month \n",
    "           - Set to_date to last day of specified month\n",
    "           Example: \"1/1 to 31/1\" in {current_year} -> from_date: 01/01/{current_year}, to_date: 31/01/{current_year}\n",
    "           \n",
    "        5. If no date is specified:\n",
    "           - Set date_range as \"N/A\"\n",
    "           - Set both from_date and to_date as \"N/A\"\n",
    "           \n",
    "        If no relevant keywords are detected, return 'All' (except for dates, you must fill 'N/A').\n",
    "        If the date range is not specified, please return 'N/A' for date_range.\n",
    "        If the product is not specified, please return 'All' for product.\n",
    "        If the product detail is not specified, please return 'All' for product_detail.\n",
    "        If the level is not specified, please return 'All' for level.\n",
    "        If the user is not specified, please return 'N/A' for user.\n",
    "        \n",
    "        Here is the list of product and product detail you should detect:\n",
    "        {parameter_properties}\n",
    "    \"\"\"\n",
    "    few_shot: str = \"\"\"\n",
    "        # Example 1:\n",
    "        ## User: Get me a Win Loss Detail Report on day 10\n",
    "        ## Output:\n",
    "        {{\n",
    "            \"date_range\": \"day 10\",\n",
    "            \"from_date\": \"10/{current_month}/{current_year}\",\n",
    "            \"to_date\": \"10/{current_month}/{current_year}\",\n",
    "            \"product\": \"All\",\n",
    "            \"product_detail\": \"All\",\n",
    "            \"level\": \"All\",\n",
    "            \"user\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Example 2:\n",
    "        ## User: Get me a Win Loss Detail Report for Direct Member who played Product Detail Sportsbook in Sportsbook Product from 01/02/2024 to 15/02/2024\n",
    "        ## Output:\n",
    "        {{\n",
    "            \"date_range\": \"01/02/2024 to 15/02/2024\",\n",
    "            \"from_date\": \"01/02/2024\",\n",
    "            \"to_date\": \"15/02/2024\",\n",
    "            \"product\": \"Sportsbook\",\n",
    "            \"product_detail\": \"Sportsbook\",\n",
    "            \"level\": \"Direct Member\",\n",
    "            \"user\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Example 3:\n",
    "        ## User: Get me a Win Loss Detail Report for Super Agent who played Product Detail SABA Basketball in SABA Basketball Product from 01/02/2024 to 15/02/2024\n",
    "        ## Output:\n",
    "        {{\n",
    "            \"date_range\": \"01/02/2024 to 15/02/2024\",\n",
    "            \"from_date\": \"01/02/2024\",\n",
    "            \"to_date\": \"15/02/2024\",\n",
    "            \"product\": \"SABA Basketball\",\n",
    "            \"product_detail\": \"SABA Basketball\",\n",
    "            \"level\": \"Super Agent\",\n",
    "            \"user\": \"N/A\"\n",
    "        }}\n",
    "        \n",
    "        Example 4:\n",
    "        ## User: Win/Loss details for Product Sportsbook\n",
    "        ## Output:\n",
    "        {{\n",
    "            \"date_range\": \"N/A\",\n",
    "            \"from_date\": \"N/A\",\n",
    "            \"to_date\": \"N/A\",\n",
    "            \"product\": \"Sportsbook\",\n",
    "            \"product_detail\": \"All\",\n",
    "            \"level\": \"All\",\n",
    "            \"user\": \"N/A\"\n",
    "        }}\n",
    "    \"\"\"\n",
    "    system_prompt: str = \"\"\"\n",
    "    You are an AI assistant majoring for Named Entity Recognition trained to extract entity and categorize queries for Winlost Report Detail\n",
    "    \"\"\"\n",
    "    user_prompt: str = \"\"\"\n",
    "\n",
    "        User request: {query}\n",
    "    \n",
    "        Current date: {current_date}\n",
    "        Current year: {current_year}\n",
    "        Current month: {current_month}\n",
    "\n",
    "        {instruction}\n",
    "\n",
    "        {few_shot}\n",
    "    \"\"\"\n",
    "    format_schema: Dict[str, Any] = dataclasses.field(default_factory=lambda: {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"date_range\": {\"type\": \"string\"},\n",
    "            \"from_date\": {\"type\": \"string\"},\n",
    "            \"to_date\": {\"type\": \"string\"},\n",
    "            \"product\": {\"type\": \"string\"},\n",
    "            \"product_detail\": {\"type\": \"string\"},\n",
    "            \"level\": {\"type\": \"string\"},\n",
    "            \"user\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"date_range\", \"from_date\", \"to_date\", \"product\", \"product_detail\", \"level\", \"user\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = '2525'\n",
    "current_year = '2525'   \n",
    "current_month = '2525'\n",
    "query = 'Get me a Win Loss Detail Report on day 10'\n",
    "parameter_properties = 'All'\n",
    "user_prompt = NERAgentConfig().user_prompt.format(\n",
    "    query=query, \n",
    "    current_date=current_date,\n",
    "    current_year=current_year,\n",
    "    current_month=current_month,\n",
    "    instruction=NERAgentConfig().instruction.format(\n",
    "        query=query,\n",
    "        current_date=current_date,\n",
    "        current_year=current_year,\n",
    "        current_month=current_month,\n",
    "        parameter_properties=parameter_properties\n",
    "    ), \n",
    "    few_shot=NERAgentConfig().few_shot.format(\n",
    "        current_month=current_month,\n",
    "        current_year=current_year,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"./output_hybrib_search.csv\", encoding='iso-8859-1', use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 1744/1744 [1:15:22<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import tqdm\n",
    "\n",
    "class Verify(BaseModel):\n",
    "    matching: int\n",
    "\n",
    "verify = []\n",
    "\n",
    "for i in tqdm.tqdm(range(data.shape[0]), colour='green'):\n",
    "    \n",
    "    query = data['Question'][i]\n",
    "    ground_truth = data['Sample'][i]\n",
    "    hybrid_search = data['AnswerbyHybribsearch'][i]\n",
    "    \n",
    "    \n",
    "    context = f''' \n",
    "        I have a question: {query}\n",
    "\n",
    "        This is the correct answer: {ground_truth}\n",
    "\n",
    "        This is the predicted answer: {hybrid_search}\n",
    "\n",
    "        Please help me verify whether the correct answer and the predicted answer match based on the keywords in both type of answers.\n",
    "\n",
    "        If they match, return 1; otherwise, return 0.\n",
    "    '''\n",
    "\n",
    "    response = chat(\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': context,\n",
    "            }\n",
    "        ],\n",
    "        model='llama3.2:latest',\n",
    "        format=Verify.model_json_schema(),\n",
    "    )\n",
    "\n",
    "    result = Verify.model_validate_json(response.message.content)\n",
    "    verify.append(result.matching)\n",
    "    \n",
    "    df_results = pl.DataFrame({\n",
    "        'query': data['Question'][:i+1],\n",
    "        'ground_truth': data['Sample'][:i+1],\n",
    "        'predict_from_hybrid_search': data['AnswerbyHybribsearch'][:i+1],\n",
    "        'score_matching': verify\n",
    "    })\n",
    "\n",
    "    \n",
    "    df_results.write_csv(\"./hani_hybrid_verified.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score_matching</th><th>count</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>457</td></tr><tr><td>0</td><td>1024</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────────────┬───────┐\n",
       "│ score_matching ┆ count │\n",
       "│ ---            ┆ ---   │\n",
       "│ i64            ┆ u32   │\n",
       "╞════════════════╪═══════╡\n",
       "│ 1              ┆ 457   │\n",
       "│ 0              ┆ 1024  │\n",
       "└────────────────┴───────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.filter(\n",
    "    pl.col('score_matching').is_in([0, 1])\n",
    ")['score_matching'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def extract_keyword_by_llama32(query:str):\n",
    "  \n",
    "  \n",
    "  url = 'http://localhost:11434/api/chat'\n",
    "\n",
    "  context = f'''\n",
    "  Extract the most relevant keywords from the following sentence: '{query}'. \n",
    "  Focus on important nouns, verbs, and adjectives that convey the core meaning. \n",
    "  Additionally, categorize the query into a relevant topic or section (e.g., Technology, Business, Health, Education, etc.).\n",
    "  For each extracted keyword, provide a list of synonyms that accurately reflect its meaning in the given context. \n",
    "  Ensure that the synonyms include common alternatives, domain-specific terms (if applicable), \n",
    "  and variations in different registers (formal, informal, technical, etc.).\n",
    "  '''\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\": \"application/json\"\n",
    "  }\n",
    "\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"You are an AI assistant trained to extract keywords and categorize queries.\"},\n",
    "      {\"role\": \"user\", \"content\": context}\n",
    "  ]\n",
    "\n",
    "  model='llama3.2:latest'\n",
    "\n",
    "  format={\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"keywords\": {\n",
    "          \"type\": \"array\",\n",
    "          'items': {\n",
    "            'type': 'string'\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"keywords\"\n",
    "      ]\n",
    "    }\n",
    "\n",
    "  data = {\n",
    "      \"model\": model,\n",
    "      \"messages\": messages,\n",
    "      \"format\": format,\n",
    "      \"stream\": False\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      try:\n",
    "          print(response.json())\n",
    "      except json.JSONDecodeError:\n",
    "          print(\"Invalid JSON response:\", response.text)\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}, {response.text}\")\n",
    "      \n",
    "  keywords = json.loads(response.json()['message']['content'])['keywords']\n",
    "  \n",
    "  return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'created_at': '2025-03-03T07:10:19.530484Z', 'message': {'role': 'assistant', 'content': '{ \"keywords\": [\"software engineer\", \"become\", \"How to\"] }'}, 'done_reason': 'stop', 'done': True, 'total_duration': 921803200, 'load_duration': 19863300, 'prompt_eval_count': 162, 'prompt_eval_duration': 43000000, 'eval_count': 18, 'eval_duration': 857000000}\n"
     ]
    }
   ],
   "source": [
    "t = extract_keyword_by_llama32(query = 'How to become a software engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['software engineer', 'become', 'How to']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
